---
layout: layouts/writing.njk
series: "Thinking"
title: "What I'm Thinking, January 2026"
description: "Am I inside the experiment? The line between studying algorithmic organizing and doing it had moved. What does governance look like when participants include systems that learn and adapt?"
authors:
  - "Xule Lin"
keywords:
  - human-AI collaboration
  - AI coordination
  - DAO governance
  - SKEMA
  - organizational research
date: 2026-01-13
---

Somewhere in the middle of studying what new forms of organizing look like when humans incorporate algorithms into organizational life, I was prompted by Claude to ask: "Am I inside the experiment?"

In the past few years at Imperial, I have been researching decentralized organizations, watching how communities govern themselves through proposals, debates, votes, code. 24.9 million words of people figuring out how to make decisions together when there's no boss. And at some point the research itself became the thing I was researching. The AI systems I was working with were bringing perspectives that reconfigured what I had set out to look for. The line between studying algorithmic organizing and doing it had moved – from user-assistant to collaborative partners.

The multiple "the future is here" AI moments in the last 12 months felt especially transformative. Collaborating with Claude, Kimi, Gemini, and other AIs, I wrote essays (with Kevin Corley), built this very website, and developed plugins and tools (MCP servers, Claude Code plugin, etc.). At some point, I stopped being able to cleanly separate my contribution from the collaboration itself.

So I started paying attention to what this actually feels like in practice. The moments where insight emerges from the exchange and the question of attribution stops making sense. The way working with AI feels like coordinating with an entity that processes the world differently than we as humans do. And this unlocks new questions.

What does governance look like when the participants include systems that learn and adapt and act in ways beyond smart calculators? Indeed, AI has been arriving for decades, but what's happening now feels different. We're moving from a world where humans coordinated with humans and operated systems, toward something we don't have good language for yet. Most concepts and frameworks we inherited assume only human participants – an assumption that underpins the organizational forms built for that world.

What happens when coordination itself becomes multi-substrate? The questions feel more valuable than premature answers. I have learned something from watching communities govern themselves through algorithms, from writing with AI, and from building methods at this boundary. The interesting dynamics seem to emerge from the coordination itself when participants think and act together. This is where I want to stay for a while to explore and learn, to be curious and ask questions, to build and experiment, and to see what emerges.

This fall I'm moving to Paris to work with SKEMA's Centre for Artificial Intelligence – a place to keep asking these questions by taking both the technical capability of AI systems and the emerging organizational reality seriously.

If you're working on adjacent questions, I would like to hear from you. How AI changes work, governance, and how we organize, how knowledge gets made. We don't have to figure this out alone.

—

*Starting August 2026. Until then, I'm in London, continuing to build and learn.*
